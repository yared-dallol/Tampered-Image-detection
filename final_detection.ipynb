{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cce8e63c-84e0-4a14-b994-f9d5a504d092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from skimage.color  import rgb2ycbcr \n",
    "from skimage.feature import local_binary_pattern\n",
    "from scipy.fftpack import  dct\n",
    "from sklearn.decomposition import PCA\n",
    "import skimage.io as io\n",
    "import numpy as np\n",
    "import progressbar\n",
    "import glob\n",
    "import cv2\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "252d87e2-2e8a-42f4-b723-0fc1225b4620",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc62d2b9-e4fc-46fe-bbb8-f0f76dd254d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lbp_dct(blocks):\n",
    "    n_points = 8\n",
    "    radius = 1\n",
    "    # Extract feature vector from given blocks\n",
    "    # Input: List of blocks response with given image\n",
    "    # Output: Feature vector of given image\n",
    "    n_blocks, block_size, _, _ = blocks.shape\n",
    "    CR_feature = np.zeros((n_blocks, block_size, block_size))\n",
    "    CB_feature = np.zeros((n_blocks, block_size, block_size))\n",
    "    for idx, block in enumerate(blocks):\n",
    "        CR_lbp          = local_binary_pattern(block[:, :, 0], n_points, radius)\n",
    "        CR_lbp          = np.float32(CR_lbp)\n",
    "        CR_feature[idx] = dct(CR_lbp)\n",
    "        \n",
    "        CB_lbp          = local_binary_pattern(block[:, :, 1], n_points, radius)\n",
    "        CB_lbp          = np.float32(CB_lbp)\n",
    "        CB_feature[idx] = dct(CB_lbp)\n",
    "    CR_feature = np.std(CR_feature, axis = 0).flatten()\n",
    "    CB_feature = np.std(CB_feature, axis = 0).flatten()\n",
    "    return np.concatenate([CR_feature, CB_feature], axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f928273d-e7f3-48d9-8d39-dbe503bdc28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(authentic_list, forged_list):\n",
    "    # Read and extract feature vector from given list images\n",
    "    block_sizes = [8]\n",
    "    strides = [16]\n",
    "    \n",
    "    Y_train = np.zeros((len(authentic_list) + len(forged_list), ), dtype = np.float32)\n",
    "    Y_train[: len(authentic_list)] = 1.0\n",
    "    X_train=[]\n",
    "    list_img= authentic_list + forged_list\n",
    "    total_img = len(authentic_list) + len(forged_list)\n",
    "    dim = 0\n",
    "    for i in range(len(block_sizes)):\n",
    "        dim += block_sizes[i] ** 2\n",
    "    features = np.zeros((total_img, 2*dim))\n",
    "    for idx in progressbar.progressbar(range(total_img)):\n",
    "        im         = list_img[idx]\n",
    "        #bgr_img    = io.imread(im)\n",
    "        #extract chromatic channel\n",
    "        #ycrcb_image = rgb2ycbcr(bgr_img[:,:,:3])  \n",
    "        bgr_img    = cv2.imread(im)\n",
    "        ycrcb_image = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2YCR_CB)\n",
    "        ycrcb_image=ycrcb_image[:, :, 1:]\n",
    "        \n",
    "        #img_hsv = convert_colorspace(bgr_img, 'RGB', 'YCbCr')\n",
    "        #ycrcb_image=img_hsv[:, :, 1:]\n",
    "        tmp        = 0\n",
    "        for k, bz in enumerate(block_sizes):\n",
    "            stride=strides[k]\n",
    "             \n",
    "            #block processing\n",
    "            height, width, _ = ycrcb_image.shape\n",
    "            img_blocks = []\n",
    "            for i in range(0, height - bz, stride):\n",
    "                for j in range(0, width - bz, stride):\n",
    "                    img_blocks.append(ycrcb_image[i: i + bz, j: j + bz])\n",
    "                    \n",
    "            img_blocks=np.array(img_blocks)\n",
    "            features[idx, tmp: tmp + 2*bz**2] = extract_lbp_dct(img_blocks)\n",
    "            tmp += 2*bz ** 2\n",
    "        X_train=features\n",
    "    return X_train, Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0aa99bd2-7cbf-4b85-970a-dfcbee33fd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetature Extraction Starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (12560 of 12560) |##################| Elapsed Time: 1:11:32 Time:  1:11:32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetature Extraction done\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU'):\n",
    "    if __name__ == '__main__':\n",
    "        authentic_folder = ['CASIA2/Au/*.jpg']\n",
    "        forged_folder = ['CASIA2/Tp/*.jpg', 'CASIA2/Tp/*.tif']\n",
    "        print('Fetature Extraction Starting...')\n",
    "        authentic_list = []\n",
    "        forged_list = []\n",
    "        for au_img in authentic_folder:\n",
    "            authentic_list += glob.glob(au_img)\n",
    "        for tp_img in forged_folder:\n",
    "            forged_list += glob.glob(tp_img)\n",
    "        X,Y=extract_feature(authentic_list,forged_list)\n",
    "        X, Y = shuffle(X, Y)\n",
    "        print('Fetature Extraction done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9c8e91fb-f4c1-4017-859c-8998c98f62d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12560, 128)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "36da563d-f2a3-47f0-bc8b-26d83b76925d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reatain 96% of original data\n",
    "pca = PCA(.96)\n",
    "X_pca=X_train\n",
    "pca.fit(X_pca)\n",
    "X_pca = pca.transform(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "84fc5a89-9854-4b69-86dc-0b30714b9e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12560, 25)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bfe1618c-ff90-416e-9c79-0fef1c23e708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1006   19]\n",
      " [  64 1423]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96      1025\n",
      "         1.0       0.99      0.96      0.97      1487\n",
      "\n",
      "    accuracy                           0.97      2512\n",
      "   macro avg       0.96      0.97      0.97      2512\n",
      "weighted avg       0.97      0.97      0.97      2512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(X_pca, Y,test_size=0.20, stratify=Y, random_state=42)\n",
    "svclassifier = SVC(kernel='rbf')\n",
    "svclassifier.fit(trainX, trainY)\n",
    "predY = svclassifier.predict(testX)\n",
    "#confusion Matricx and classification report\n",
    "print(confusion_matrix(testY,predY))\n",
    "print(classification_report(testY,predY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d3cbfb7b-3112-4768-bdde-713a9d857ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building SVM Model...\n",
      "Accuracy: 0.96 (+/- 0.01)\n",
      "Building SVM Model Done.\n"
     ]
    }
   ],
   "source": [
    "print('Building SVM Model...')\n",
    "scaler  = StandardScaler()\n",
    "X_train = scaler.fit_transform(X)\n",
    "clf = LinearSVC(dual=False)\n",
    "#cross-validated with 10 fold\n",
    "scores = cross_val_score(clf,X_train,Y ,cv=10, scoring='f1_macro')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print('Building SVM Model Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cdd0e29b-9dd4-4883-98a1-76f5d63233e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10048, 5, 5, 1) (2512, 5, 5, 1)\n",
      "(10048, 1) (2512, 1)\n",
      "(10048, 2) (2512, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainX_cnn=trainX\n",
    "testX_cnn=testX\n",
    "trainY_cnn=trainY\n",
    "testY_cnn=testY\n",
    "#(trainX, testX, trainY, testY) = train_test_split(trainX, trainY,test_size=0.20, stratify=trainY, random_state=42)\n",
    "\n",
    "trainX_cnn = trainX_cnn.reshape(trainX_cnn.shape[0],5,5,1) \n",
    "testX_cnn = testX_cnn.reshape(testX_cnn.shape[0],5,5,1) \n",
    "print(np.shape(trainX_cnn), np.shape(testX_cnn))\n",
    "\n",
    "trainY_cnn = trainY_cnn.reshape(trainY_cnn.shape[0],1) \n",
    "testY_cnn = testY_cnn.reshape(testY_cnn.shape[0],1) \n",
    "print(np.shape(trainY_cnn), np.shape(testY_cnn))\n",
    "\n",
    "trainY_cnn = tf.keras.utils.to_categorical(trainY_cnn)\n",
    "testY_cnn = tf.keras.utils.to_categorical(testY_cnn)\n",
    "print(np.shape(trainY_cnn), np.shape(testY_cnn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f8b425bd-d5e6-4e18-b61a-b1a16d3567d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a convolutional neural network\n",
    "model = tf.keras.models.Sequential([\n",
    "\n",
    "    # Convolutional layer. Learn 32 filters using a 3x3 kernel\n",
    "    tf.keras.layers.Conv2D(\n",
    "        32, (3, 3), activation=\"relu\", input_shape=(5,5,1)\n",
    "    ),\n",
    "\n",
    "    # Max-pooling layer, using 2x2 pool size\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    # Flatten units\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    # Add a hidden layer with dropout\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "    # Add an output layer with output units for all  2 output\n",
    "    tf.keras.layers.Dense(2, activation=\"softmax\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6af499ea-ce95-439b-aee8-c6f91ff924d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "314/314 [==============================] - 4s 10ms/step - loss: 0.0950 - accuracy: 0.9624\n",
      "Epoch 2/20\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 0.0895 - accuracy: 0.9637\n",
      "Epoch 3/20\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 0.0934 - accuracy: 0.9625\n",
      "Epoch 4/20\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0896 - accuracy: 0.9641\n",
      "Epoch 5/20\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0903 - accuracy: 0.9658\n",
      "Epoch 6/20\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0875 - accuracy: 0.9643\n",
      "Epoch 7/20\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 0.0850 - accuracy: 0.9642\n",
      "Epoch 8/20\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 0.0854 - accuracy: 0.9658\n",
      "Epoch 9/20\n",
      "314/314 [==============================] - 4s 11ms/step - loss: 0.0836 - accuracy: 0.9643 0s - loss: 0.0827 - ac - ETA: 0s - loss: 0.0832 - accuracy: 0.\n",
      "Epoch 10/20\n",
      "314/314 [==============================] - 4s 12ms/step - loss: 0.0862 - accuracy: 0.9649\n",
      "Epoch 11/20\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 0.0844 - accuracy: 0.9655\n",
      "Epoch 12/20\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 0.0818 - accuracy: 0.9645\n",
      "Epoch 13/20\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 0.0807 - accuracy: 0.9665\n",
      "Epoch 14/20\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 0.0803 - accuracy: 0.9664\n",
      "Epoch 15/20\n",
      "314/314 [==============================] - 3s 9ms/step - loss: 0.0773 - accuracy: 0.9676\n",
      "Epoch 16/20\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 0.0805 - accuracy: 0.9681\n",
      "Epoch 17/20\n",
      "314/314 [==============================] - 5s 15ms/step - loss: 0.0823 - accuracy: 0.9664\n",
      "Epoch 18/20\n",
      "314/314 [==============================] - 4s 11ms/step - loss: 0.0774 - accuracy: 0.9671\n",
      "Epoch 19/20\n",
      "314/314 [==============================] - 4s 12ms/step - loss: 0.0792 - accuracy: 0.9673\n",
      "Epoch 20/20\n",
      "314/314 [==============================] - 4s 11ms/step - loss: 0.0743 - accuracy: 0.9690 2s - loss: 0.068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23a2956d9d0>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train neural network\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "model.fit(trainX_cnn, trainY_cnn, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a3832bd4-c6db-4686-8ccb-d5f1e8031923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 - 2s - loss: 0.1052 - accuracy: 0.9586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10521959513425827, 0.9585987329483032]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(testX_cnn,testY_cnn,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b9cf2f0b-1055-445f-b4fb-ccef97432a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "[[ 986   39]\n",
      " [  65 1422]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      1025\n",
      "           1       0.97      0.96      0.96      1487\n",
      "\n",
      "    accuracy                           0.96      2512\n",
      "   macro avg       0.96      0.96      0.96      2512\n",
      "weighted avg       0.96      0.96      0.96      2512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "# make predictions on the testing set\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predIdxs = model.predict(testX_cnn)\n",
    "\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "\n",
    "# show a nicely formatted classification report\n",
    "print(confusion_matrix(testY_cnn.argmax(axis=1), predIdxs))\n",
    "print(classification_report(testY_cnn.argmax(axis=1), predIdxs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3916ae17-370a-4cff-a682-71b9e62c0aed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
